{"title":"Probabilidade Condicional e Independência","markdown":{"yaml":{"title":"Probabilidade Condicional e Independência","lang":"pt","toc":true,"toc-title":"Nesta página","toc-location":"right","execute":{"warning":false,"message":false},"format":{"html":{"code-fold":true,"code-summary":"Mostrar Código"}}},"headingText":"Probabilidade Condicional","containsRefs":false,"markdown":"\n\n\n**Definição** Sejam dois eventos $A$ e $B$ definidos no mesmo espaço de probabilidade, a *probabilidade condicional* de $A$ dado o evento $B$, denotado por $P(A|B)$ é definido por\n\n$$\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\ \\ \\ \\ se \\ P(B) > 0,\n$$\n\ne é indefinida se $P(B) = 0$. Um resultado direto dessa definição é que $P(A|B)P(B) = P(B|A)P(A)$.\n\n\n\n*Exemplo* Suponha o lançamento de um Dado Honesto, ou seja, $\\Omega = \\{\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}$, qual a probabilidade de sair o número 2, dado que saiu um número par?\n\nSeja,\n\n- $A$: sair o número 2\n- $B$: sair par\n\n$$\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(\\text{sair 2 e par})}{P(\\text{par})}  \\overset{A \\subset B}{=} \\frac{P(\\text{sair 2})}{P(\\text{par})}  = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\n$$\n\nNote que \"dado o evento $B$\" significa dizer que o \"evento $B$\" ocorreu e, sendo assim, \"limitamos\" o espaço amostral para o evento B. Ou seja, não estamos mais trabalhando com $\\Omega$, mas sim somente com os elementos do evento $B$ sendo possíveis. Dado isto, será que este novo cenário satisfazem os axiomas de Kolmogorov caso $P(B)>0$? A resposta é **sim**, pois:\n\n- $P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\ge 0, \\forall A \\in \\mathcal{F}$\n- $P(\\Omega|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1$\n- Se $A_1, A_2, ...$ são mutuamente excludentes de $\\mathcal{F}$, então\n\n$$\nP\\left( \\bigcup_{i=1}^{n} A_i |B \\right) = \\frac{P\\left( \\left(\\bigcup_{i=1}^{n} A_i \\right)\\cap B \\right)}{P(B)} \\overset{Lei \\ Distributiva}{=} \\frac{P\\left( \\bigcup_{i=1}^{n} \\left(A_i \\cap B \\right)\\right)}{P(B)} = \\frac{\\sum_{i=1}^{n}P\\left( A_i \\cap B \\right)}{P(B)} = \\sum_{i=1}^{n}\\left(\\frac{P(A_i \\cap B) }{P(B)}\\right) = \\sum_{i=1}^{n}P\\left( A_i | B \\right)\n$$\nDesta maneira, para quaquer $B$ satisfazendo $P(B) > 0$, qualquer função de probabilidade aplicada no subespaço de $B$ também é uma função de probabilidade e goza das mesmas propriedades de uma função não-condicionada.\n\n## Teorema da Probabilidade Total\n\nAntes de apresentar o teorema da probabilidade total, apresenta-se a definição de **partição** do espaço amostral:\n\n**Definição** Se $B_1, B_2, ..., B_n$ representa um conjunto de eventos mutuamente excludentes satisfazendo $\\Omega = \\bigcup\\limits_{i=1}^{n}B_i$ então, dizemos que $B_1, B_2, ..., B_n$ forma uma *partição* de $\\Omega$.\n\n**Teorema** Se $B_1, B_2, ..., B_n$ forma uma *partição* de $\\Omega$ então para qualquer evento $A$:\n\n$$\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n$$\n\nVisualmente:\n\n![Exemplo de uma partição de $\\Omega$ para $n = 5$ e um evento A (extraído de @degroot2012probability)](figs/particao_total.png)\n\nRessalta-se que o *Teorema da Probabilidade Total* vale também quando $n = \\infty$\n\n## Teorema de Bayes\n\nO Teorema de Bayese, [na sua forma extendida](https://en.wikipedia.org/wiki/Bayes%27_theorem)^[Um vídeo interessante sobre a aplicação e explicação do Teorema de Bayes pode ser visto aqui: [A Armadilha Bayesiana](https://www.youtube.com/watch?v=R13BD8qKeTg)], é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\n\n**Teorema** Se $B_1, B_2, ..., B_n$ forma uma *partição* de $\\Omega$ então para qualquer evento $A$ temos que\n\n$$\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n$$\nRessalta-se que o *Teorema de Bayes* vale também quando $n = \\infty$.\n\nObserve que o **denominador** da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\n\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se $B_i$ é um evento condicionado à um evento $A$, então querer saber $P(B_i|A)$ é como se fosse no sentido de retrospectiva (\"backward\"). É como se fosse **questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento**. Por isso, o Teorema de Bayes também é chamado de *teorema da probabilidade a posteriori* (@morettin1999estatística).\n\n**Exemplo** Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces \"caras\". Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face \"cara\". Então, dado que saiu \"cara\", qual a probabilidade de eu ter sorteado a moeda viciada? \n\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n![Ilustração de experimento de duas fases](figs/moedas_particao.png)\n\nOriginalmente, $P(B_3) = \\frac{1}{3}$, no entanto, a probabilidade condicionada a posteriori é:\n\n$$\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n$$\n\nOu seja, note que a probabilidade \"atualizou\" de $\\frac{1}{3}$ para $\\frac{1}{2}$.\n\n## Regra da multiplicação\n\nOutro resultado importante é a regra da multiplicação abaixo:\n\n\n**Teorema** Sejam $A_1, A_2, ..., A_n$ diferentes eventos de um espaço de probabilidade, então:\n\n$$\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n$$\n\nOu, conforme @mood1974introduction, em notação alternativa: \n\n$$\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n$$\n\n\n\n# Independência de eventos\n\n**Definição** Os eventos $A$ e $B$ definidos no mesmo espaço de probabilidade são considerados *independentes* se, e somente se:\n\n- $P(A \\cap B) = P(A)P(B)$\n\nNote que, se a igualdade acima valer, então:\n\n- $P(A | B) = P(A),\\ se\\ P(B) > 0$\n- $P(B | A) = P(B),\\ se\\ P(A) > 0$\n\n\n**Definição** (*Independência de múltiplos eventos*) Os eventos $A_1,A_2,...,A_n$ definidos no mesmo espaço de probabilidade são considerados conjuntamente *independentes* se, e somente se:\n\n\n$$\nP\\left( \\bigcap_{i=1}^{n} A_i \\right) = \\prod_{i=1}^{n} P\\left(  A_i \\right).\n$$","srcMarkdownNoYaml":"\n\n# Probabilidade Condicional\n\n**Definição** Sejam dois eventos $A$ e $B$ definidos no mesmo espaço de probabilidade, a *probabilidade condicional* de $A$ dado o evento $B$, denotado por $P(A|B)$ é definido por\n\n$$\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\ \\ \\ \\ se \\ P(B) > 0,\n$$\n\ne é indefinida se $P(B) = 0$. Um resultado direto dessa definição é que $P(A|B)P(B) = P(B|A)P(A)$.\n\n\n\n*Exemplo* Suponha o lançamento de um Dado Honesto, ou seja, $\\Omega = \\{\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}$, qual a probabilidade de sair o número 2, dado que saiu um número par?\n\nSeja,\n\n- $A$: sair o número 2\n- $B$: sair par\n\n$$\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(\\text{sair 2 e par})}{P(\\text{par})}  \\overset{A \\subset B}{=} \\frac{P(\\text{sair 2})}{P(\\text{par})}  = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\n$$\n\nNote que \"dado o evento $B$\" significa dizer que o \"evento $B$\" ocorreu e, sendo assim, \"limitamos\" o espaço amostral para o evento B. Ou seja, não estamos mais trabalhando com $\\Omega$, mas sim somente com os elementos do evento $B$ sendo possíveis. Dado isto, será que este novo cenário satisfazem os axiomas de Kolmogorov caso $P(B)>0$? A resposta é **sim**, pois:\n\n- $P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\ge 0, \\forall A \\in \\mathcal{F}$\n- $P(\\Omega|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1$\n- Se $A_1, A_2, ...$ são mutuamente excludentes de $\\mathcal{F}$, então\n\n$$\nP\\left( \\bigcup_{i=1}^{n} A_i |B \\right) = \\frac{P\\left( \\left(\\bigcup_{i=1}^{n} A_i \\right)\\cap B \\right)}{P(B)} \\overset{Lei \\ Distributiva}{=} \\frac{P\\left( \\bigcup_{i=1}^{n} \\left(A_i \\cap B \\right)\\right)}{P(B)} = \\frac{\\sum_{i=1}^{n}P\\left( A_i \\cap B \\right)}{P(B)} = \\sum_{i=1}^{n}\\left(\\frac{P(A_i \\cap B) }{P(B)}\\right) = \\sum_{i=1}^{n}P\\left( A_i | B \\right)\n$$\nDesta maneira, para quaquer $B$ satisfazendo $P(B) > 0$, qualquer função de probabilidade aplicada no subespaço de $B$ também é uma função de probabilidade e goza das mesmas propriedades de uma função não-condicionada.\n\n## Teorema da Probabilidade Total\n\nAntes de apresentar o teorema da probabilidade total, apresenta-se a definição de **partição** do espaço amostral:\n\n**Definição** Se $B_1, B_2, ..., B_n$ representa um conjunto de eventos mutuamente excludentes satisfazendo $\\Omega = \\bigcup\\limits_{i=1}^{n}B_i$ então, dizemos que $B_1, B_2, ..., B_n$ forma uma *partição* de $\\Omega$.\n\n**Teorema** Se $B_1, B_2, ..., B_n$ forma uma *partição* de $\\Omega$ então para qualquer evento $A$:\n\n$$\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n$$\n\nVisualmente:\n\n![Exemplo de uma partição de $\\Omega$ para $n = 5$ e um evento A (extraído de @degroot2012probability)](figs/particao_total.png)\n\nRessalta-se que o *Teorema da Probabilidade Total* vale também quando $n = \\infty$\n\n## Teorema de Bayes\n\nO Teorema de Bayese, [na sua forma extendida](https://en.wikipedia.org/wiki/Bayes%27_theorem)^[Um vídeo interessante sobre a aplicação e explicação do Teorema de Bayes pode ser visto aqui: [A Armadilha Bayesiana](https://www.youtube.com/watch?v=R13BD8qKeTg)], é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\n\n**Teorema** Se $B_1, B_2, ..., B_n$ forma uma *partição* de $\\Omega$ então para qualquer evento $A$ temos que\n\n$$\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n$$\nRessalta-se que o *Teorema de Bayes* vale também quando $n = \\infty$.\n\nObserve que o **denominador** da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\n\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se $B_i$ é um evento condicionado à um evento $A$, então querer saber $P(B_i|A)$ é como se fosse no sentido de retrospectiva (\"backward\"). É como se fosse **questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento**. Por isso, o Teorema de Bayes também é chamado de *teorema da probabilidade a posteriori* (@morettin1999estatística).\n\n**Exemplo** Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces \"caras\". Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face \"cara\". Então, dado que saiu \"cara\", qual a probabilidade de eu ter sorteado a moeda viciada? \n\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n![Ilustração de experimento de duas fases](figs/moedas_particao.png)\n\nOriginalmente, $P(B_3) = \\frac{1}{3}$, no entanto, a probabilidade condicionada a posteriori é:\n\n$$\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n$$\n\nOu seja, note que a probabilidade \"atualizou\" de $\\frac{1}{3}$ para $\\frac{1}{2}$.\n\n## Regra da multiplicação\n\nOutro resultado importante é a regra da multiplicação abaixo:\n\n\n**Teorema** Sejam $A_1, A_2, ..., A_n$ diferentes eventos de um espaço de probabilidade, então:\n\n$$\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n$$\n\nOu, conforme @mood1974introduction, em notação alternativa: \n\n$$\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n$$\n\n\n\n# Independência de eventos\n\n**Definição** Os eventos $A$ e $B$ definidos no mesmo espaço de probabilidade são considerados *independentes* se, e somente se:\n\n- $P(A \\cap B) = P(A)P(B)$\n\nNote que, se a igualdade acima valer, então:\n\n- $P(A | B) = P(A),\\ se\\ P(B) > 0$\n- $P(B | A) = P(B),\\ se\\ P(A) > 0$\n\n\n**Definição** (*Independência de múltiplos eventos*) Os eventos $A_1,A_2,...,A_n$ definidos no mesmo espaço de probabilidade são considerados conjuntamente *independentes* se, e somente se:\n\n\n$$\nP\\left( \\bigcap_{i=1}^{n} A_i \\right) = \\prod_{i=1}^{n} P\\left(  A_i \\right).\n$$"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"4_probabilidade_condicional_e_independencia.html"},"language":{"toc-title-document":"Índice","toc-title-website":"Nesta página","related-formats-title":"Outros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fonte","other-links-title":"Outros Links","code-links-title":"Ligações de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Caderno do Artigo","notebook-preview-download":"Baixar Caderno","notebook-preview-download-src":"Descarregar código fonte","notebook-preview-back":"Voltar ao Artigo","manuscript-meca-bundle":"Arquivo MECA","section-title-abstract":"Resumo","section-title-appendices":"Apêndices","section-title-footnotes":"Notas de rodapé","section-title-references":"Referências","section-title-reuse":"Reuso","section-title-copyright":"Direito autoral","section-title-citation":"Citação","appendix-attribution-cite-as":"Por favor, cite este trabalho como:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Ver Licença","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Afiliação","title-block-affiliation-plural":"Afiliações","title-block-published":"Data de Publicação","title-block-modified":"Data de Modificação","title-block-keywords":"Palavras-chave","callout-tip-title":"Dica","callout-note-title":"Nota","callout-warning-title":"Aviso","callout-important-title":"Importante","callout-caution-title":"Cuidado","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar o código","code-tools-hide-all-code":"Esconder o código","code-tools-view-source":"Ver o código fonte","code-tools-source-code":"Código fonte","tools-share":"Share","tools-download":"Download","code-line":"Linha","code-lines":"Linhas","copy-button-tooltip":"Copiar para a área de transferência","copy-button-tooltip-success":"Copiada","repo-action-links-edit":"Editar essa página","repo-action-links-source":"Ver o código fonte","repo-action-links-issue":"Criar uma issue","back-to-top":"De volta ao topo","search-no-results-text":"Nenhum resultado","search-matching-documents-text":"documentos correspondentes","search-copy-link-title":"Copiar link para a busca","search-hide-matches-text":"Esconder correspondências adicionais","search-more-match-text":"mais correspondência neste documento","search-more-matches-text":"mais correspondências neste documento","search-clear-button-title":"Limpar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Procurar","toggle-section":"Alternar seção","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo escuro","toggle-reader-mode":"Alternar modo de leitor","toggle-navigation":"Alternar de navegação","crossref-fig-title":"Figura","crossref-tbl-title":"Tabela","crossref-lst-title":"Listagem","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolário","crossref-prp-title":"Proposição","crossref-cnj-title":"Conjetura","crossref-def-title":"Definição","crossref-exm-title":"Exemplo","crossref-exr-title":"Exercício","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apêndice","crossref-sec-prefix":"Seção","crossref-eq-prefix":"Equação","crossref-lof-title":"Lista de Figuras","crossref-lot-title":"Lista de Tabelas","crossref-lol-title":"Lista de Listagens","environment-proof-title":"Comprovação","environment-remark-title":"Comentário","environment-solution-title":"Solução","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Pré-selecionado","listing-page-order-by-date-asc":"Mais velho","listing-page-order-by-date-desc":"O mais novo","listing-page-order-by-number-desc":"Decrescente","listing-page-order-by-number-asc":"Crescente","listing-page-field-date":"Data","listing-page-field-title":"Título","listing-page-field-description":"Descrição","listing-page-field-author":"Autor","listing-page-field-filename":"Nome do arquivo","listing-page-field-filemodified":"Arquivo modificado","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tempo de leitura","listing-page-field-wordcount":"Contagem de Palavras","listing-page-field-categories":"Categorias","listing-page-minutes-compact":"{0} minutos","listing-page-category-all":"Tudo","listing-page-no-matches":"Nenhum item correspondente","listing-page-words":"{0} palavras","listing-page-filter":"Filtro","draft":"Rascunho"},"metadata":{"lang":"pt","fig-responsive":true,"quarto-version":"1.6.42","editor":"visual","bibliography":["../references.bib"],"theme":["cosmo"],"title":"Probabilidade Condicional e Independência","toc-title":"Nesta página","toc-location":"right","code-summary":"Mostrar Código"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}