---
title: "Probabilidade Condicional e Independência"
lang: pt # Equações ficarem referenciadas em Português

toc: true
toc-title: "Nesta página"
toc-location: right

execute: 
  warning: false
  message: false

format:
  html:
    code-fold: true
    code-summary: "Mostrar Código"
---

# Probabilidade Condicional

**Definição** Sejam dois eventos $A$ e $B$ definidos no mesmo espaço de probabilidade, a *probabilidade condicional* de $A$ dado o evento $B$, denotado por $P(A|B)$ é definido por

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}, \ \ \ \ se \ P(B) > 0,
$$

e é indefinida se $P(B) = 0$. Um resultado direto dessa definição é que $P(A|B)P(B) = P(B|A)P(A)$.



*Exemplo* Suponha o lançamento de um Dado Honesto, ou seja, $\Omega = \{\{1\}, \{2\}, \{3\}, \{4\}, \{5\}, \{6\}\}$, qual a probabilidade de sair o número 2, dado que saiu um número par?

Seja,

- $A$: sair o número 2
- $B$: sair par

$$
P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(\text{sair 2 e par})}{P(\text{par})}  \overset{A \subset B}{=} \frac{P(\text{sair 2})}{P(\text{par})}  = \frac{\frac{1}{6}}{\frac{1}{2}} = \frac{1}{3}
$$

Note que "dado o evento $B$" significa dizer que o "evento $B$" ocorreu e, sendo assim, "limitamos" o espaço amostral para o evento B. Ou seja, não estamos mais trabalhando com $\Omega$, mas sim somente com os elementos do evento $B$ sendo possíveis. Dado isto, será que este novo cenário satisfazem os axiomas de Kolmogorov caso $P(B)>0$? A resposta é **sim**, pois:

- $P(A|B) = \frac{P(A \cap B)}{P(B)} \ge 0, \forall A \in \mathcal{F}$
- $P(\Omega|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B)}{P(B)} = 1$
- Se $A_1, A_2, ...$ são mutuamente excludentes de $\mathcal{F}$, então

$$
P\left( \bigcup_{i=1}^{n} A_i |B \right) = \frac{P\left( \left(\bigcup_{i=1}^{n} A_i \right)\cap B \right)}{P(B)} \overset{Lei \ Distributiva}{=} \frac{P\left( \bigcup_{i=1}^{n} \left(A_i \cap B \right)\right)}{P(B)} = \frac{\sum_{i=1}^{n}P\left( A_i \cap B \right)}{P(B)} = \sum_{i=1}^{n}\left(\frac{P(A_i \cap B) }{P(B)}\right) = \sum_{i=1}^{n}P\left( A_i | B \right)
$$
Desta maneira, para quaquer $B$ satisfazendo $P(B) > 0$, qualquer função de probabilidade aplicada no subespaço de $B$ também é uma função de probabilidade e goza das mesmas propriedades de uma função não-condicionada.

## Teorema da Probabilidade Total

Antes de apresentar o teorema da probabilidade total, apresenta-se a definição de **partição** do espaço amostral:

**Definição** Se $B_1, B_2, ..., B_n$ representa um conjunto de eventos mutuamente excludentes satisfazendo $\Omega = \bigcup\limits_{i=1}^{n}B_i$ então, dizemos que $B_1, B_2, ..., B_n$ forma uma *partição* de $\Omega$.

**Teorema** Se $B_1, B_2, ..., B_n$ forma uma *partição* de $\Omega$ então para qualquer evento $A$:

$$
P(A) = P\left(\bigcup\limits_{i=1}^{n}(A \cap B_i)\right) = \sum\limits_{i=1}^{n}P(A \cap B_i) = \sum\limits_{i=1}^{n}P(A | B_i)P(B_i)
$$

Visualmente:

![Exemplo de uma partição de $\Omega$ para $n = 5$ e um evento A (extraído de @degroot2012probability)](figs/particao_total.png)

Ressalta-se que o *Teorema da Probabilidade Total* vale também quando $n = \infty$

## Teorema de Bayes

O Teorema de Bayese, [na sua forma extendida](https://en.wikipedia.org/wiki/Bayes%27_theorem)^[Um vídeo interessante sobre a aplicação e explicação do Teorema de Bayes pode ser visto aqui: [A Armadilha Bayesiana](https://www.youtube.com/watch?v=R13BD8qKeTg)], é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:

**Teorema** Se $B_1, B_2, ..., B_n$ forma uma *partição* de $\Omega$ então para qualquer evento $A$ temos que

$$
P(B_i |A) = \frac{P(A | B_i) P(B_i)} {\sum\limits_{i=1}^{n}P(A | B_i)P(B_i)} \ \ \ \forall i=1,...n.
$$
Ressalta-se que o *Teorema de Bayes* vale também quando $n = \infty$.

Observe que o **denominador** da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.

O Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se $B_i$ é um evento condicionado à um evento $A$, então querer saber $P(B_i|A)$ é como se fosse no sentido de retrospectiva ("backward"). É como se fosse **questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento**. Por isso, o Teorema de Bayes também é chamado de *teorema da probabilidade a posteriori* (@morettin1999estatística).

**Exemplo** Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces "caras". Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face "cara". Então, dado que saiu "cara", qual a probabilidade de eu ter sorteado a moeda viciada? 

Podemos pensar neste problema da seguinte forma ilustrativa:

![Ilustração de experimento de duas fases](figs/moedas_particao.png)

Originalmente, $P(B_3) = \frac{1}{3}$, no entanto, a probabilidade condicionada a posteriori é:

$$
P(B_3|A) = \frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \frac{1 \times \frac{1}{3}} {\frac{1}{2} \times \frac{1}{3} + \frac{1}{2} \times \frac{1}{3} + 1\times \frac{1}{3}} = \frac{\frac{1}{3}}{\frac{4}{6}} = \frac{1}{2}
$$

Ou seja, note que a probabilidade "atualizou" de $\frac{1}{3}$ para $\frac{1}{2}$.

## Regra da multiplicação

Outro resultado importante é a regra da multiplicação abaixo:


**Teorema** Sejam $A_1, A_2, ..., A_n$ diferentes eventos de um espaço de probabilidade, então:

$$
P(A_1 \cap A_2 \cap ... \cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \cap A_1)...P(A_n|A_1 \cap ... \cap A_{n-1})
$$

Ou, conforme @mood1974introduction, em notação alternativa: 

$$
P(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})
$$



# Independência de eventos

**Definição** Os eventos $A$ e $B$ definidos no mesmo espaço de probabilidade são considerados *independentes* se, e somente se:

- $P(A \cap B) = P(A)P(B)$

Note que, se a igualdade acima valer, então:

- $P(A | B) = P(A),\ se\ P(B) > 0$
- $P(B | A) = P(B),\ se\ P(A) > 0$


**Definição** (*Independência de múltiplos eventos*) Os eventos $A_1,A_2,...,A_n$ definidos no mesmo espaço de probabilidade são considerados conjuntamente *independentes* se, e somente se:


$$
P\left( \bigcap_{i=1}^{n} A_i \right) = \prod_{i=1}^{n} P\left(  A_i \right).
$$